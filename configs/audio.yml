define: &f_size 256
define: &low_level_ch 2
define: &flatten_ch 512
define: &t_size 1024


data:
    dataset: AUDIO
    dataset_kwargs:
        path: downloads
        f_size: *f_size
        t_size: *t_size
        virtual_samplerate: 48000
        use_numpy: False
        dtype: torch.BFloat16Tensor
        device: cuda
        axis: CTF
    logit_transform: false
    uniform_dequantization: false
    gaussian_dequantization: false
    random_flip: false
    rescaled: false

    num_workers: 4

model:
    dtype: null

    transformers:
        imports: "import transformers; from transformers.models.fnet.modeling_fnet import FNetEncoder"
        module: FNetEncoder
        config: transformers.FNetConfig
        kwargs:
            hidden_size: *flatten_ch
            num_hidden_layers: 12
            intermediate_size: 2048
            hidden_act: gelu_new
            hidden_dropout_prob: 0.1
            initializer_range: 0.02
            layer_norm_eps: 1e-12
        channels: *flatten_ch
        dtype: torch.cuda.BFloat16Tensor

    channels: *low_level_ch
    t_size: *t_size
    f_size: *f_size

    preprocessing_residual:
        channels: 32
        kernal: [3, 3, 3, 3, 3, 3]
    postprocessing_residual:
        channels: 32
        kernal: [3, 3, 3, 3, 3, 3]
    
    var_type: fixedlarge
    ema_rate: 0.9999
    ema: True
    resamp_with_conv: True

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
    num_diffusion_timesteps: 1000

training:
    batch_size: 6
    n_epochs: null
    n_iters: 5000000
    snapshot_freq: 5000
    validation_freq: 2000

sampling:
    batch_size: 64
    last_only: True

optim:
    weight_decay: 0.0000001
    optimizer: "Adam"
    lr: 0.0001
    beta1: 0.9
    amsgrad: false
    eps: 0.00000001
    grad_clip: 1
